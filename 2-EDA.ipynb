{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet Water Level Outliers\n",
    "\n",
    "Use water level measurements of groundwater available from IntellusNM.com to identify outliers, trend, seasonality, and upset events.\n",
    "\n",
    "This notebook contains basic statistical analysis and visualization of the data.\n",
    "\n",
    "### Data Sources\n",
    "- summary : Processed file from notebook 1-Data_Prep\n",
    "\n",
    "### Changes\n",
    "- 02-19-2024 : Started project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import prophet\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "in_file = Path.cwd() / \"data\" / \"processed\" / f\"summary_{today:%b-%d-%Y}.pkl\"\n",
    "report_dir = Path.cwd() / \"reports\"\n",
    "report_file = report_dir / \"Excel_Analysis_{today:%b-%d-%Y}.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(in_file)\n",
    "df = df.rename(columns={'Measurement Date Time':'ds', 'Groundwater Elevation':'y'})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Data Analysis - Loop through locations to identify anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = df[['Location ID','Site ID']].drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {'N':'X', 'Y':'o'}\n",
    "hue_order = ['N','Y']\n",
    "style_order = ['N','Y']\n",
    "iw = 0.99\n",
    "\n",
    "\n",
    "for location, site_id in zip(location['Location ID'], location['Site ID']):\n",
    "\t# Add seasonality and instantiate a new Prophet model\n",
    "\tmodel = Prophet(interval_width=iw, yearly_seasonality=True, weekly_seasonality=True)\n",
    "\n",
    "\t# print(location, parameter)\n",
    "\texport_subset = df[(df['Location ID'] == location) & (df['Site ID'] == site_id)]\n",
    "\t\n",
    "\texport_subset = export_subset[export_subset.groupby(['Location ID']).transform('size')>10]\n",
    "\n",
    "\tif export_subset.empty:\n",
    "\t\tcontinue\n",
    "\n",
    "\t# Fit the model on the training dataset\n",
    "\tmodel.fit(export_subset)\n",
    "\n",
    "\t# Make prediction\n",
    "\tforecast = model.predict(export_subset)\n",
    "\n",
    "\t# Merge actual and predicted values\n",
    "\tperformance = pd.merge(export_subset, forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds')\n",
    "\n",
    "\t# Create an anomaly indicator\n",
    "\tperformance['anomaly'] = performance.apply(lambda rows: 1 if ((rows.y<rows.yhat_lower)|(rows.y>rows.yhat_upper)) else 0, axis = 1)\n",
    "\n",
    "\tanomalies = performance[performance['anomaly']==1].sort_values(by='ds')\n",
    "\tif anomalies.empty:\n",
    "\t\tcontinue\n",
    "\t\n",
    "\tanomalies.to_csv('anomalies.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload anomalies and prepare for graphing of results with anomalies identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_location_parameter = pd.read_csv('anomalies.csv', header=None, names = ('site_id','location_id','sample_date_time','groundwater_measurement','groundwater_elevation','groundwater_level_comment','groundwater_level_data_quality_code','groundwater_level_data_quality_reason_code','yhat','yhat_lower','yhat_upper','anomaly'))\n",
    "outlier_location_parameter['sample_date_time'] = pd.to_datetime(outlier_location_parameter['sample_date_time'])\n",
    "outlier_location_parameter = outlier_location_parameter[outlier_location_parameter['sample_date_time']>pd.to_datetime('2018-05-01')]\n",
    "outlier_location_parameter = outlier_location_parameter[['location_id','site_id','sample_date_time']].drop_duplicates()\n",
    "# outlier_location_parameter.to_csv('recent_anomalies.csv', index=False, header=False)\n",
    "outlier_location_parameter.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {'N':'X', 'Y':'o'}\n",
    "hue_order = ['N','Y']\n",
    "style_order = ['N','Y']\n",
    "\n",
    "\n",
    "for location, site in zip(outlier_location_parameter['location_id'],outlier_location_parameter['site_id']):\n",
    "\t# Add seasonality and instantiate a new Prophet model\n",
    "\tmodel = Prophet()\n",
    "\tmodel = Prophet(interval_width=iw, yearly_seasonality=True, weekly_seasonality=True)\n",
    "\n",
    "\t# print(location, parameter)\n",
    "\n",
    "\texport_subset = df[(df['Location ID'] == location) & (df['Site ID'] == site)]\n",
    "\n",
    "\tif export_subset.empty:\n",
    "\t\tcontinue\n",
    "\n",
    "\t# Fit the model on the training dataset\n",
    "\tmodel.fit(export_subset)\n",
    "\n",
    "\t# Make prediction\n",
    "\tforecast = model.predict(export_subset)\n",
    "\n",
    "\t# Merge actual and predicted values\n",
    "\tperformance = pd.merge(export_subset, forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds')\n",
    "\n",
    "\t# Create an anomaly indicator\n",
    "\tperformance['anomaly'] = performance.apply(lambda rows: 1 if ((rows.y<rows.yhat_lower)|(rows.y>rows.yhat_upper)) else 0, axis = 1)\n",
    "\n",
    "\tanomalies = performance[performance['anomaly']==1].sort_values(by='ds')\n",
    "\t# if anomalies.empty:\n",
    "\t# \tcontinue\n",
    "\t\n",
    "\t# Visualize the anomalies\n",
    "\tfig = model.plot(forecast); \n",
    "\t\n",
    "\t# a = add_changepoints_to_plot(fig.gca(), model, forecast)# Add semi-colon to remove the duplicated chart\n",
    "\n",
    "\t# py.iplot(fig)\n",
    "\n",
    "\tname = (location +' '+ site + ' outliers.png').replace(\"/\",\"-\")\n",
    "\ty_axis_label = site  + \" \" + 'Groundwater Elevation (ft)'\n",
    "\tplt.ylabel(y_axis_label)\n",
    "\tplt.xlabel('Sample Collection Date')\n",
    "\tplt.suptitle('\\n'+location)\n",
    "\tfig.savefig('reports/' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
